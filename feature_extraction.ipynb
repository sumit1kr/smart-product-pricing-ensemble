{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ram_safe_multimodal.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "import gc\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ============================================================\n",
        "# RAM-SAFE CONFIG\n",
        "# ============================================================\n",
        "class SafeConfig:\n",
        "    # Text settings\n",
        "    TEXT_MODEL = 'all-MiniLM-L6-v2'  # Lightweight text model\n",
        "\n",
        "    # Image settings\n",
        "    IMG_SIZE = 128  # 128x128 images\n",
        "    BATCH_SIZE = 1  # Process ONE sample at a time\n",
        "    TIMEOUT = 3\n",
        "\n",
        "    # Chunk processing\n",
        "    CHUNK_SIZE = 1000  # Small chunks\n",
        "    SAVE_EVERY = 500   # Save progress every 500 samples\n",
        "\n",
        "# ============================================================\n",
        "# 1. LOAD MODELS ONCE\n",
        "# ============================================================\n",
        "def load_models_once():\n",
        "    \"\"\"Load models once and keep in memory\"\"\"\n",
        "    print(\"üöÄ Loading models...\")\n",
        "\n",
        "    # Text model (lightweight)\n",
        "    text_model = SentenceTransformer(SafeConfig.TEXT_MODEL)\n",
        "\n",
        "    # Image model (ResNet18 - works with 128x128)\n",
        "    img_model = models.resnet18(pretrained=True)\n",
        "    img_model = nn.Sequential(*(list(img_model.children())[:-1]))  # Remove classifier\n",
        "    img_model.eval()\n",
        "\n",
        "    # Image transforms for 128x128\n",
        "    img_transform = transforms.Compose([\n",
        "        transforms.Resize((SafeConfig.IMG_SIZE, SafeConfig.IMG_SIZE)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                           std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    return text_model, img_model, img_transform\n",
        "\n",
        "# ============================================================\n",
        "# 2. PROCESS SINGLE SAMPLE (MEMORY EFFICIENT)\n",
        "# ============================================================\n",
        "def process_single_sample(text, image_url, text_model, img_model, img_transform):\n",
        "    \"\"\"Process one sample - minimal memory usage\"\"\"\n",
        "    try:\n",
        "        # TEXT: Get embedding\n",
        "        text_emb = text_model.encode([str(text)], convert_to_numpy=True)[0]\n",
        "\n",
        "        # IMAGE: Download and process if URL exists\n",
        "        if pd.notna(image_url) and str(image_url).startswith('http'):\n",
        "            try:\n",
        "                response = requests.get(image_url, timeout=SafeConfig.TIMEOUT)\n",
        "                image = Image.open(BytesIO(response.content)).convert('RGB')\n",
        "                image_tensor = img_transform(image).unsqueeze(0)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    img_emb = img_model(image_tensor).squeeze().numpy()\n",
        "\n",
        "                # Force cleanup\n",
        "                del image_tensor, image\n",
        "\n",
        "            except Exception as e:\n",
        "                img_emb = np.zeros(512)  # Fallback for image errors\n",
        "        else:\n",
        "            img_emb = np.zeros(512)\n",
        "\n",
        "        # Combine features\n",
        "        combined = np.concatenate([text_emb, img_emb])\n",
        "\n",
        "        return combined\n",
        "\n",
        "    except Exception as e:\n",
        "        # Return zero features if anything fails\n",
        "        return np.zeros(384 + 512)\n",
        "\n",
        "# ============================================================\n",
        "# 3. PROCESS CHUNK AND SAVE TO DISK\n",
        "# ============================================================\n",
        "def process_chunk_to_disk(chunk_data, text_model, img_model, img_transform, chunk_id, output_dir):\n",
        "    \"\"\"Process one chunk and immediately save to disk\"\"\"\n",
        "    chunk_texts, chunk_urls, chunk_indices = chunk_data\n",
        "\n",
        "    print(f\"üî® Processing chunk {chunk_id} ({len(chunk_texts)} samples)...\")\n",
        "\n",
        "    features_list = []\n",
        "\n",
        "    for i, (text, url, idx) in enumerate(tqdm(zip(chunk_texts, chunk_urls, chunk_indices), total=len(chunk_texts))):\n",
        "        # Process single sample\n",
        "        features = process_single_sample(text, url, text_model, img_model, img_transform)\n",
        "        features_list.append(features)\n",
        "\n",
        "        # Aggressive memory cleanup\n",
        "        if i % 50 == 0:\n",
        "            gc.collect()\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "    # Convert to array and save to disk immediately\n",
        "    features_array = np.array(features_list)\n",
        "    np.save(os.path.join(output_dir, f'features_chunk_{chunk_id}.npy'), features_array)\n",
        "\n",
        "    print(f\"üíæ Saved chunk {chunk_id} to disk\")\n",
        "\n",
        "    # Clean up\n",
        "    del features_list, features_array\n",
        "    gc.collect()\n",
        "\n",
        "    return len(chunk_texts)\n",
        "\n",
        "# ============================================================\n",
        "# 4. MAIN RAM-SAFE EXTRACTION\n",
        "# ============================================================\n",
        "def ram_safe_extraction(train_df, test_df):\n",
        "    \"\"\"\n",
        "    Extract multimodal features without RAM crashes\n",
        "    \"\"\"\n",
        "    print(\"‚ö° RAM-SAFE MULTIMODAL EXTRACTION\")\n",
        "\n",
        "    # Create output directory\n",
        "    output_dir = \"temp_features\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Combine all data\n",
        "    all_texts = list(train_df['catalog_content'])\n",
        "    all_urls = list(train_df['image_link'])\n",
        "    all_indices = list(range(len(train_df)))\n",
        "\n",
        "    # Add test data\n",
        "    all_texts.extend(list(test_df['catalog_content']))\n",
        "    all_urls.extend(list(test_df['image_link']))\n",
        "    all_indices.extend(list(range(len(train_df), len(train_df) + len(test_df))))\n",
        "\n",
        "    total_samples = len(all_texts)\n",
        "    print(f\"üìä Processing {total_samples} samples in chunks...\")\n",
        "\n",
        "    # Load models ONCE\n",
        "    text_model, img_model, img_transform = load_models_once()\n",
        "\n",
        "    # Process in small chunks\n",
        "    processed_count = 0\n",
        "    chunk_files = []\n",
        "\n",
        "    for chunk_start in range(0, total_samples, SafeConfig.CHUNK_SIZE):\n",
        "        chunk_end = min(chunk_start + SafeConfig.CHUNK_SIZE, total_samples)\n",
        "        chunk_id = chunk_start // SafeConfig.CHUNK_SIZE\n",
        "\n",
        "        chunk_data = (\n",
        "            all_texts[chunk_start:chunk_end],\n",
        "            all_urls[chunk_start:chunk_end],\n",
        "            all_indices[chunk_start:chunk_end]\n",
        "        )\n",
        "\n",
        "        # Process chunk and save to disk\n",
        "        count = process_chunk_to_disk(chunk_data, text_model, img_model, img_transform, chunk_id, output_dir)\n",
        "        processed_count += count\n",
        "        chunk_files.append(f'features_chunk_{chunk_id}.npy')\n",
        "\n",
        "        print(f\"üìç Progress: {processed_count}/{total_samples} samples\")\n",
        "\n",
        "    # Load all chunks from disk and combine\n",
        "    print(\"üîó Combining chunks from disk...\")\n",
        "\n",
        "    all_features = []\n",
        "    for chunk_file in chunk_files:\n",
        "        chunk_path = os.path.join(output_dir, chunk_file)\n",
        "        chunk_data = np.load(chunk_path)\n",
        "        all_features.append(chunk_data)\n",
        "\n",
        "        # Delete file after loading to save space\n",
        "        os.remove(chunk_path)\n",
        "\n",
        "    # Combine all features\n",
        "    all_features = np.vstack(all_features)\n",
        "\n",
        "    # Clean up temp directory\n",
        "    os.rmdir(output_dir)\n",
        "\n",
        "    # Split back to train/test\n",
        "    train_size = len(train_df)\n",
        "    train_features = all_features[:train_size]\n",
        "    test_features = all_features[train_size:train_size + len(test_df)]\n",
        "\n",
        "    print(f\"‚úÖ EXTRACTION COMPLETE!\")\n",
        "    print(f\"üìä Train features: {train_features.shape}\")\n",
        "    print(f\"üìä Test features: {test_features.shape}\")\n",
        "\n",
        "    return train_features, test_features\n",
        "\n",
        "# ============================================================\n",
        "# 5. HYBRID APPROACH (TEXT + IMAGE METADATA)\n",
        "# ============================================================\n",
        "def hybrid_fast_extraction(train_df, test_df):\n",
        "    \"\"\"\n",
        "    Ultra-fast hybrid: Text embeddings + Image metadata (no image download)\n",
        "    Takes 20-30 minutes for 150K samples\n",
        "    \"\"\"\n",
        "    print(\"üéØ ULTRA-FAST HYBRID EXTRACTION\")\n",
        "\n",
        "    # TEXT: Fast embeddings\n",
        "    text_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "    all_texts = list(train_df['catalog_content']) + list(test_df['catalog_content'])\n",
        "    print(\"üìù Encoding texts...\")\n",
        "    text_embeddings = text_model.encode(all_texts, batch_size=512, show_progress_bar=True)\n",
        "\n",
        "    # IMAGE: Metadata only (no download)\n",
        "    print(\"üñºÔ∏è Extracting image metadata...\")\n",
        "    image_metadata = []\n",
        "    for url in list(train_df['image_link']) + list(test_df['image_link']):\n",
        "        metadata = {\n",
        "            'has_image': 1 if pd.notna(url) and str(url).startswith('http') else 0,\n",
        "            'is_amazon': 1 if 'amazon' in str(url).lower() else 0,\n",
        "            'url_length': len(str(url)),\n",
        "            'has_jpg': 1 if '.jpg' in str(url).lower() else 0,\n",
        "        }\n",
        "        image_metadata.append(list(metadata.values()))\n",
        "\n",
        "    image_metadata = np.array(image_metadata)\n",
        "\n",
        "    # Combine\n",
        "    all_features = np.hstack([text_embeddings, image_metadata])\n",
        "\n",
        "    # Split back\n",
        "    train_size = len(train_df)\n",
        "    train_features = all_features[:train_size]\n",
        "    test_features = all_features[train_size:train_size + len(test_df)]\n",
        "\n",
        "    print(f\"‚úÖ HYBRID features: {train_features.shape}\")\n",
        "    return train_features, test_features\n",
        "\n",
        "# ============================================================\n",
        "# 6. FAST SUBMISSION\n",
        "# ============================================================\n",
        "def create_fast_submission(train_features, test_features, train_df, test_df):\n",
        "    \"\"\"Create submission in 5 minutes\"\"\"\n",
        "    from sklearn.ensemble import ExtraTreesRegressor\n",
        "\n",
        "    print(\"üéØ Creating submission...\")\n",
        "\n",
        "    X = train_features\n",
        "    y = train_df['price'].values\n",
        "    X_test = test_features\n",
        "\n",
        "    model = ExtraTreesRegressor(\n",
        "        n_estimators=100,\n",
        "        max_depth=20,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    model.fit(X, y)\n",
        "    predictions = model.predict(X_test)\n",
        "\n",
        "    submission = pd.DataFrame({\n",
        "        'sample_id': test_df['sample_id'],\n",
        "        'price': predictions\n",
        "    })\n",
        "\n",
        "    submission['price'] = submission['price'].clip(lower=0.1)\n",
        "    submission.to_csv('ram_safe_submission.csv', index=False)\n",
        "\n",
        "    print(\"‚úÖ SUBMISSION CREATED!\")\n",
        "    return submission\n",
        "\n",
        "# ============================================================\n",
        "# 7. MAIN EXECUTION\n",
        "# ============================================================\n",
        "if __name__ == \"__main__\":\n",
        "    import time\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Install: pip install sentence-transformers torchvision\n",
        "\n",
        "    # Load data\n",
        "    train_df = pd.read_csv(\"train_cleaned.csv\")\n",
        "    test_df = pd.read_csv(\"test_cleaned.csv\")\n",
        "\n",
        "    print(f\"üì• Loaded: Train {train_df.shape}, Test {test_df.shape}\")\n",
        "\n",
        "    # Choose extraction method\n",
        "    print(\"Choose extraction method:\")\n",
        "    print(\"1. RAM-SAFE Multimodal (1-1.5 hours)\")\n",
        "    print(\"2. HYBRID Fast (20-30 minutes)\")\n",
        "\n",
        "    choice = input(\"Enter choice (1 or 2): \").strip()\n",
        "\n",
        "    if choice == \"1\":\n",
        "        try:\n",
        "            print(\"üöÄ RAM-SAFE MULTIMODAL EXTRACTION...\")\n",
        "            train_features, test_features = ram_safe_extraction(train_df, test_df)\n",
        "            mode = \"multimodal\"\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Multimodal failed: {e}\")\n",
        "            print(\"üîÑ Falling back to hybrid...\")\n",
        "            train_features, test_features = hybrid_fast_extraction(train_df, test_df)\n",
        "            mode = \"hybrid_fallback\"\n",
        "    else:\n",
        "        print(\"üéØ HYBRID FAST EXTRACTION...\")\n",
        "        train_features, test_features = hybrid_fast_extraction(train_df, test_df)\n",
        "        mode = \"hybrid\"\n",
        "\n",
        "    # Create submission\n",
        "    submission = create_fast_submission(train_features, test_features, train_df, test_df)\n",
        "\n",
        "    total_time = (time.time() - start_time) / 60\n",
        "    print(f\"‚è±Ô∏è  TOTAL TIME: {total_time:.1f} minutes\")\n",
        "    print(f\"üéØ MODE: {mode}\")\n",
        "    print(\"üéâ SUCCESS! No RAM crashes!\")"
      ],
      "metadata": {
        "id": "RuBoP-Behs0u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}